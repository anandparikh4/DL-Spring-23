{"cells":[{"cell_type":"markdown","metadata":{},"source":["Imports"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T05:05:06.709208Z","iopub.status.busy":"2023-04-15T05:05:06.708735Z","iopub.status.idle":"2023-04-15T05:05:06.718498Z","shell.execute_reply":"2023-04-15T05:05:06.717374Z","shell.execute_reply.started":"2023-04-15T05:05:06.709169Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["import torch\n","from torch import nn , optim, Tensor\n","from torch.autograd.variable import Variable\n","from torch.utils.data import Dataset , DataLoader\n","from torchvision import transforms , datasets\n","from PIL import Image\n","import glob\n","device = torch.device('cpu')\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["Parameters and hyperparameters"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T05:05:06.721691Z","iopub.status.busy":"2023-04-15T05:05:06.720852Z","iopub.status.idle":"2023-04-15T05:05:06.733196Z","shell.execute_reply":"2023-04-15T05:05:06.732022Z","shell.execute_reply.started":"2023-04-15T05:05:06.721610Z"},"trusted":true},"outputs":[],"source":["CHANNELS = 3                    # 3 channels - RGB\n","NUM_EPOCHS = 80                 # No. of epochs 80 (tradeoff between reasonable training time and good results)\n","BATCH_SIZE = 16                \n","IMAGE_SIZE = 256\n","MASK_SIZE = 75\n","CHECKPOINT_INTERVAL = 100       # Save models after training on 100 batches"]},{"cell_type":"markdown","metadata":{},"source":["Generator Definition"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T05:05:06.735707Z","iopub.status.busy":"2023-04-15T05:05:06.735018Z","iopub.status.idle":"2023-04-15T05:05:06.750255Z","shell.execute_reply":"2023-04-15T05:05:06.749203Z","shell.execute_reply.started":"2023-04-15T05:05:06.735669Z"},"trusted":true},"outputs":[],"source":["# Generator Model layers (for detailed description, refer the final Report)\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","\n","        self.generator_model = nn.Sequential(\n","            nn.Conv2d(CHANNELS, 64, 4, stride=2, padding=1),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(64, 64, 4, stride=2, padding=1),\n","            nn.BatchNorm2d(64, 0.8),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n","            nn.BatchNorm2d(128, 0.8),\n","            nn.LeakyReLU(0.2),         \n","            nn.Conv2d(128, 128, 4, stride=2, padding=1),\n","            nn.BatchNorm2d(128, 0.8),\n","            nn.LeakyReLU(0.2),            \n","            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n","            nn.BatchNorm2d(256, 0.8),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(256, 512, 4, stride=2, padding=1),\n","            nn.BatchNorm2d(512, 0.8),\n","            nn.LeakyReLU(0.2),           \n","            nn.Conv2d(512, 4000, 4),\n","            nn.ConvTranspose2d(4000, 512, 4, stride=1, padding=0),\n","            nn.BatchNorm2d(512, 0.8),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),\n","            nn.BatchNorm2d(256, 0.8),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n","            nn.BatchNorm2d(128, 0.8),\n","            nn.ReLU(),           \n","            nn.ConvTranspose2d(128, 128, 4, stride=2, padding=1),\n","            nn.BatchNorm2d(128, 0.8),\n","            nn.ReLU(),            \n","            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n","            nn.BatchNorm2d(64, 0.8),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64, 64, 4, stride=2, padding=1),\n","            nn.BatchNorm2d(64, 0.8),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64, CHANNELS, 4, stride=2, padding=1),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, x):\n","        return self.generator_model(x)"]},{"cell_type":"markdown","metadata":{},"source":["Discriminator Definition"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T05:05:06.752369Z","iopub.status.busy":"2023-04-15T05:05:06.751509Z","iopub.status.idle":"2023-04-15T05:05:06.766464Z","shell.execute_reply":"2023-04-15T05:05:06.765419Z","shell.execute_reply.started":"2023-04-15T05:05:06.752329Z"},"trusted":true},"outputs":[],"source":["# Discriminator Model layers (for detailed description, refer the final Report)\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","\n","        self.discriminator_model = nn.Sequential(\n","            nn.Conv2d(CHANNELS, 64, 4, 2, 1),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, 128, 4, 2, 1),\n","            nn.InstanceNorm2d(128),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(128, 256, 4, 2, 1),\n","            nn.InstanceNorm2d(256),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(256, 512, 4, 2, 1),\n","            nn.InstanceNorm2d(512),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(512, 1, 3, 1, 1)\n","        )\n","\n","    def forward(self, x):\n","        return self.discriminator_model(x)"]},{"cell_type":"markdown","metadata":{},"source":["Create models, initialize weights, loss functions and optimizers (partially commented)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T05:05:06.770598Z","iopub.status.busy":"2023-04-15T05:05:06.770237Z","iopub.status.idle":"2023-04-15T05:05:07.573404Z","shell.execute_reply":"2023-04-15T05:05:07.572107Z","shell.execute_reply.started":"2023-04-15T05:05:06.770570Z"},"trusted":true},"outputs":[],"source":["# Initialize the weights for faster convergence\n","def init_weights(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        m.weight.data.normal_(0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)\n","        \n","# Create models\n","g_model = Generator()\n","g_model.to(device)\n","d_model = Discriminator()\n","d_model.to(device)\n","\n","# UNCOMMENTING THE FOLLOWING 4 LINES WILL RE-INITIALIZE THE MODELS (do only for retraining)\n","# g_model.apply(init_weights)\n","# torch.save(g_model.state_dict() , \"g_model.pth\")\n","# d_model.apply(init_weights)\n","# torch.save(d_model.state_dict() , \"d_model.pth\")\n","\n","# MSE and L1 loss used later\n","lossMSE = nn.MSELoss()\n","lossL1 = nn.L1Loss()\n","\n","# Adam optimizer for both generator and discriminator\n","g_optim = optim.Adam(g_model.parameters() , lr = 0.0002 , betas = (0.5 , 0.999))\n","d_optim = optim.Adam(d_model.parameters() , lr = 0.0002 , betas = (0.5 , 0.999))"]},{"cell_type":"markdown","metadata":{},"source":["Data Loader Definition"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T05:05:07.575657Z","iopub.status.busy":"2023-04-15T05:05:07.575246Z","iopub.status.idle":"2023-04-15T05:05:07.589799Z","shell.execute_reply":"2023-04-15T05:05:07.588770Z","shell.execute_reply.started":"2023-04-15T05:05:07.575616Z"},"trusted":true},"outputs":[],"source":["# Customized data loader class\n","# Version = 0 --> Training\n","# Version = 1 --> Testing\n","# For ease of use, dataset paths are hardcoded\n","class MyDataset(Dataset):\n","    def __init__(self , version):\n","        self.converter = transforms.Compose([\n","                                    transforms.ToTensor(),\n","                                    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n","                                ])\n","        self.version = version\n","        self.masked = None\n","        self.unmasked = None\n","        dataset_path = \"/kaggle/input/photo-reconstruction/Dataset\"\n","        if self.version == 0:\n","            self.unmasked = glob.glob(dataset_path + \"/Training_Data/Cat/Unmasked_Train/*.jpg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Cat/Unmasked_Train/*.jpeg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Cat/Unmasked_Train/*.png\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Dog/Unmasked_Train/*.jpg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Dog/Unmasked_Train/*.jpeg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Dog/Unmasked_Train/*.png\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Elephant/Unmasked_Train/*.jpg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Elephant/Unmasked_Train/*.jpeg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Elephant/Unmasked_Train/*.png\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Tiger/Unmasked_Train/*.jpg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Tiger/Unmasked_Train/*.jpeg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Tiger/Unmasked_Train/*.png\")\n","            self.masked   = glob.glob(dataset_path + \"/Training_Data/Cat/Masked_Train/*.jpg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Cat/Masked_Train/*.jpeg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Cat/Masked_Train/*.png\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Dog/Masked_Train/*.jpg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Dog/Masked_Train/*.jpeg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Dog/Masked_Train/*.png\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Elephant/Masked_Train/*.jpg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Elephant/Masked_Train/*.jpeg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Elephant/Masked_Train/*.png\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Tiger/Masked_Train/*.jpg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Tiger/Masked_Train/*.jpeg\") \\\n","                          + glob.glob(dataset_path + \"/Training_Data/Tiger/Masked_Train/*.png\")\n","        else:\n","            self.masked   = glob.glob(dataset_path + \"/Testing_Data/*.jpg\") \\\n","                          + glob.glob(dataset_path + \"/Testing_Data/*.jpeg\") \\\n","                          + glob.glob(dataset_path + \"/Testing_Data/*.png\")\n","\n","    def __getitem__(self , index):\n","        filename = self.masked[index % len(self.masked)]\n","        img_masked = Image.open(filename)\n","        img_masked_tensor = self.converter(img_masked)\n","        img_masked_tensor = Variable(img_masked_tensor.type(torch.cuda.FloatTensor))\n","        img_masked_tensor.to(device)\n","        if self.version == 0:\n","            # For training purposes, return both the masked and unmasked tensors, since the discriminator needs both\n","            img_unmasked = Image.open(self.unmasked[index % len(self.unmasked)])\n","            img_unmasked_tensor = self.converter(img_unmasked)\n","            img_unmasked_tensor = Variable(img_unmasked_tensor.type(torch.cuda.FloatTensor))\n","            img_unmasked_tensor.to(device)\n","            return img_masked_tensor , img_unmasked_tensor\n","        else:\n","            # For testing purposes, return masked version and the file name (file name needed for inpainting)\n","            return img_masked_tensor , filename\n","\n","    def __len__(self):\n","        return len(self.masked)"]},{"cell_type":"markdown","metadata":{},"source":["Load data into dataloader"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T05:05:07.593781Z","iopub.status.busy":"2023-04-15T05:05:07.593030Z","iopub.status.idle":"2023-04-15T05:05:07.699108Z","shell.execute_reply":"2023-04-15T05:05:07.698165Z","shell.execute_reply.started":"2023-04-15T05:05:07.593742Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["7000\n","200\n","13\n"]}],"source":["# Create train and test data loaders\n","train_data = MyDataset(0)\n","test_data = MyDataset(1)\n","\n","train_loader = DataLoader(\n","    train_data,\n","    batch_size = BATCH_SIZE,\n","    shuffle = True\n",")\n","\n","test_loader = DataLoader(\n","    test_data,\n","    batch_size = BATCH_SIZE,\n","    shuffle = False\n",")\n","\n","print(len(train_data))      # Number of training examples\n","print(len(test_data))       # Number of testing examples\n","print(len(test_loader))     # Number of testing batches (for reference)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Training Loop"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T05:05:07.700982Z","iopub.status.busy":"2023-04-15T05:05:07.700619Z","iopub.status.idle":"2023-04-15T09:00:12.479260Z","shell.execute_reply":"2023-04-15T09:00:12.478266Z","shell.execute_reply.started":"2023-04-15T05:05:07.700945Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 , Total Generator Loss = 143.85662841796875 , Total Discriminator Loss = 27.583545684814453\n","Epoch: 1 , Total Generator Loss = 120.1114501953125 , Total Discriminator Loss = 3.1595077514648438\n","Epoch: 2 , Total Generator Loss = 113.61994171142578 , Total Discriminator Loss = 1.7974348068237305\n","Epoch: 3 , Total Generator Loss = 109.79947662353516 , Total Discriminator Loss = 15.27480411529541\n","Epoch: 4 , Total Generator Loss = 106.36138916015625 , Total Discriminator Loss = 2.2146148681640625\n","Epoch: 5 , Total Generator Loss = 103.74385833740234 , Total Discriminator Loss = 0.961919903755188\n","Epoch: 6 , Total Generator Loss = 101.65727233886719 , Total Discriminator Loss = 7.520349025726318\n","Epoch: 7 , Total Generator Loss = 100.44464874267578 , Total Discriminator Loss = 1.2536975145339966\n","Epoch: 8 , Total Generator Loss = 97.4548568725586 , Total Discriminator Loss = 0.9105815291404724\n","Epoch: 9 , Total Generator Loss = 94.3191909790039 , Total Discriminator Loss = 0.7953607439994812\n","Epoch: 10 , Total Generator Loss = 92.29952239990234 , Total Discriminator Loss = 23.624719619750977\n","Epoch: 11 , Total Generator Loss = 91.31346893310547 , Total Discriminator Loss = 5.878279685974121\n","Epoch: 12 , Total Generator Loss = 90.03913879394531 , Total Discriminator Loss = 1.109140157699585\n","Epoch: 13 , Total Generator Loss = 88.53108215332031 , Total Discriminator Loss = 0.9179922938346863\n","Epoch: 14 , Total Generator Loss = 88.06786346435547 , Total Discriminator Loss = 1.0456486940383911\n","Epoch: 15 , Total Generator Loss = 87.06362915039062 , Total Discriminator Loss = 0.8460239768028259\n","Epoch: 16 , Total Generator Loss = 85.96864318847656 , Total Discriminator Loss = 14.43848705291748\n","Epoch: 17 , Total Generator Loss = 85.5099868774414 , Total Discriminator Loss = 1.0078555345535278\n","Epoch: 18 , Total Generator Loss = 84.46989440917969 , Total Discriminator Loss = 0.8341842293739319\n","Epoch: 19 , Total Generator Loss = 83.85181427001953 , Total Discriminator Loss = 1.4586315155029297\n","Epoch: 20 , Total Generator Loss = 82.96361541748047 , Total Discriminator Loss = 0.7455425262451172\n","Epoch: 21 , Total Generator Loss = 82.33008575439453 , Total Discriminator Loss = 11.019558906555176\n","Epoch: 22 , Total Generator Loss = 81.71739196777344 , Total Discriminator Loss = 0.5813153982162476\n","Epoch: 23 , Total Generator Loss = 81.36206817626953 , Total Discriminator Loss = 0.5999580025672913\n","Epoch: 24 , Total Generator Loss = 80.18484497070312 , Total Discriminator Loss = 0.6433000564575195\n","Epoch: 25 , Total Generator Loss = 79.78167724609375 , Total Discriminator Loss = 0.6121533513069153\n","Epoch: 26 , Total Generator Loss = 78.55294036865234 , Total Discriminator Loss = 11.152215003967285\n","Epoch: 27 , Total Generator Loss = 77.63308715820312 , Total Discriminator Loss = 0.7853026390075684\n","Epoch: 28 , Total Generator Loss = 77.35971069335938 , Total Discriminator Loss = 0.3560788035392761\n","Epoch: 29 , Total Generator Loss = 76.4716567993164 , Total Discriminator Loss = 0.3451431691646576\n","Epoch: 30 , Total Generator Loss = 76.28182220458984 , Total Discriminator Loss = 0.7799025177955627\n","Epoch: 31 , Total Generator Loss = 75.75859069824219 , Total Discriminator Loss = 0.35369542241096497\n","Epoch: 32 , Total Generator Loss = 75.51332092285156 , Total Discriminator Loss = 0.592867910861969\n","Epoch: 33 , Total Generator Loss = 74.82579803466797 , Total Discriminator Loss = 0.6473997235298157\n","Epoch: 34 , Total Generator Loss = 73.93260955810547 , Total Discriminator Loss = 0.4743815064430237\n","Epoch: 35 , Total Generator Loss = 73.85491180419922 , Total Discriminator Loss = 0.8610866069793701\n","Epoch: 36 , Total Generator Loss = 73.19940185546875 , Total Discriminator Loss = 0.4886537194252014\n","Epoch: 37 , Total Generator Loss = 72.62528228759766 , Total Discriminator Loss = 0.5618764758110046\n","Epoch: 38 , Total Generator Loss = 72.32650756835938 , Total Discriminator Loss = 0.6078241467475891\n","Epoch: 39 , Total Generator Loss = 72.00296783447266 , Total Discriminator Loss = 0.654862642288208\n","Epoch: 40 , Total Generator Loss = 71.51594543457031 , Total Discriminator Loss = 0.4444984793663025\n","Epoch: 41 , Total Generator Loss = 71.01368713378906 , Total Discriminator Loss = 0.43127235770225525\n","Epoch: 42 , Total Generator Loss = 70.62914276123047 , Total Discriminator Loss = 3.2137341499328613\n","Epoch: 43 , Total Generator Loss = 70.22564697265625 , Total Discriminator Loss = 0.3341275453567505\n","Epoch: 44 , Total Generator Loss = 69.96895599365234 , Total Discriminator Loss = 0.27252197265625\n","Epoch: 45 , Total Generator Loss = 69.56376647949219 , Total Discriminator Loss = 0.3276565372943878\n","Epoch: 46 , Total Generator Loss = 68.98058319091797 , Total Discriminator Loss = 0.4204987585544586\n","Epoch: 47 , Total Generator Loss = 68.8421859741211 , Total Discriminator Loss = 0.5949164628982544\n","Epoch: 48 , Total Generator Loss = 68.59944915771484 , Total Discriminator Loss = 0.2751877009868622\n","Epoch: 49 , Total Generator Loss = 68.18130493164062 , Total Discriminator Loss = 0.38385722041130066\n","Epoch: 50 , Total Generator Loss = 67.79109954833984 , Total Discriminator Loss = 0.40515923500061035\n","Epoch: 51 , Total Generator Loss = 67.54064178466797 , Total Discriminator Loss = 0.5551115870475769\n","Epoch: 52 , Total Generator Loss = 67.21791076660156 , Total Discriminator Loss = 3.742400646209717\n","Epoch: 53 , Total Generator Loss = 66.80912780761719 , Total Discriminator Loss = 0.25540053844451904\n","Epoch: 54 , Total Generator Loss = 66.40086364746094 , Total Discriminator Loss = 0.17398951947689056\n","Epoch: 55 , Total Generator Loss = 66.3230972290039 , Total Discriminator Loss = 0.1724408119916916\n","Epoch: 56 , Total Generator Loss = 65.91131591796875 , Total Discriminator Loss = 0.27895015478134155\n","Epoch: 57 , Total Generator Loss = 65.67847442626953 , Total Discriminator Loss = 0.2829582989215851\n","Epoch: 58 , Total Generator Loss = 65.49376678466797 , Total Discriminator Loss = 0.3517269790172577\n","Epoch: 59 , Total Generator Loss = 64.91182708740234 , Total Discriminator Loss = 0.6346379518508911\n","Epoch: 60 , Total Generator Loss = 64.77135467529297 , Total Discriminator Loss = 0.3151407539844513\n","Epoch: 61 , Total Generator Loss = 64.49053192138672 , Total Discriminator Loss = 0.5733464360237122\n","Epoch: 62 , Total Generator Loss = 64.2649154663086 , Total Discriminator Loss = 0.5289454460144043\n","Epoch: 63 , Total Generator Loss = 64.02852630615234 , Total Discriminator Loss = 0.3791879415512085\n","Epoch: 64 , Total Generator Loss = 64.05110931396484 , Total Discriminator Loss = 0.4878053665161133\n","Epoch: 65 , Total Generator Loss = 63.45595932006836 , Total Discriminator Loss = 0.25875043869018555\n","Epoch: 66 , Total Generator Loss = 63.267791748046875 , Total Discriminator Loss = 0.5429587960243225\n","Epoch: 67 , Total Generator Loss = 62.85359191894531 , Total Discriminator Loss = 0.6857640743255615\n","Epoch: 68 , Total Generator Loss = 62.84372329711914 , Total Discriminator Loss = 0.25722065567970276\n","Epoch: 69 , Total Generator Loss = 62.53452682495117 , Total Discriminator Loss = 0.31445154547691345\n","Epoch: 70 , Total Generator Loss = 62.177738189697266 , Total Discriminator Loss = 0.2457929253578186\n","Epoch: 71 , Total Generator Loss = 62.091522216796875 , Total Discriminator Loss = 0.5039353370666504\n","Epoch: 72 , Total Generator Loss = 61.55143737792969 , Total Discriminator Loss = 0.6551278829574585\n","Epoch: 73 , Total Generator Loss = 61.75416946411133 , Total Discriminator Loss = 0.1744914948940277\n","Epoch: 74 , Total Generator Loss = 61.43029022216797 , Total Discriminator Loss = 0.47332504391670227\n","Epoch: 75 , Total Generator Loss = 61.329200744628906 , Total Discriminator Loss = 0.3473891019821167\n","Epoch: 76 , Total Generator Loss = 60.9879264831543 , Total Discriminator Loss = 0.4315263628959656\n","Epoch: 77 , Total Generator Loss = 60.729122161865234 , Total Discriminator Loss = 0.2596518099308014\n","Epoch: 78 , Total Generator Loss = 60.511573791503906 , Total Discriminator Loss = 0.6402124762535095\n","Epoch: 79 , Total Generator Loss = 60.5574951171875 , Total Discriminator Loss = 0.40562474727630615\n"]}],"source":["# COMMENT OUT THIS WHOLE BLOCK IF YOU DO NOT WISH TO TRAIN AGAIN\n","for epoch in range(NUM_EPOCHS):\n","    epoch_g_loss = 0    # Sum of losses of all batches in one epoch for generator\n","    epoch_d_loss = 0    # Sum of losses of all batches in one epoch for discriminator\n","    for i, (masked , unmasked) in enumerate(train_loader):\n","        \n","        real_labels = Variable(torch.cuda.FloatTensor(masked.size(0),1,16,16).fill_(1.0), requires_grad=False)  # All 1's\n","        real_labels.to(device)\n","        fake_labels = Variable(torch.cuda.FloatTensor(masked.size(0),1,16,16).fill_(0.0), requires_grad=False)  # All 0's\n","        fake_labels.to(device)\n","        \n","        g_optim.zero_grad()\n","        g_out = g_model(masked)     # Generate fake unmasked image, given real masked image\n","        g_entropy = lossMSE(d_model(g_out) , real_labels)   \n","        g_reconstruct = lossL1(g_out , unmasked)\n","        g_loss = 0.001 * g_entropy + 0.999 * g_reconstruct\n","        g_loss.backward()           # Backpropagate on generator\n","        g_optim.step()\n","        \n","        d_optim.zero_grad()\n","        d_real = lossMSE(d_model(unmasked) , real_labels)       # Make predictions on real unmasked image\n","        d_fake = lossMSE(d_model(g_out.detach()) , fake_labels) # Make predictions on fake unmasked image (generator's output)\n","        d_loss = 0.5 * d_real + 0.5 * d_fake\n","        d_loss.backward()           # Backpropagate on discriminator\n","        d_optim.step()\n","        epoch_g_loss += g_loss\n","        epoch_d_loss += d_loss\n","        \n","        # Save model after each checkpoint\n","        if i % CHECKPOINT_INTERVAL == 0:\n","            torch.save(g_model , \"g_model.pth\")\n","            torch.save(d_model , \"d_model.pth\")\n","            print(f\"Epoch = {epoch}, Batch = {i} , Generator Loss = {g_loss} , Discriminator Loss = {d_loss}\")\n","    \n","    print(f\"Epoch: {epoch} , Total Generator Loss = {epoch_g_loss} , Total Discriminator Loss = {epoch_d_loss}\")"]},{"cell_type":"markdown","metadata":{},"source":["Function to generate the report"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T09:00:12.481175Z","iopub.status.busy":"2023-04-15T09:00:12.480813Z","iopub.status.idle":"2023-04-15T09:00:12.519935Z","shell.execute_reply":"2023-04-15T09:00:12.519057Z","shell.execute_reply.started":"2023-04-15T09:00:12.481138Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","data = []\n","df = pd.read_csv(\"/kaggle/input/photo-reconstruction/Dataset/Testing_Data/masked_info.csv\")\n","# Output is image Tensor of shape 3,256,256\n","# filename is only name not path\n","def add_csv(output,filename):\n","    box1_row = df[df['filename'] == filename].iloc[0]['box1_row']\n","    box1_col = df[df['filename'] == filename].iloc[0]['box1_col']\n","    box2_row = df[df['filename'] == filename].iloc[0]['box2_row']\n","    box2_col = df[df['filename'] == filename].iloc[0]['box2_col']\n","    for i in range(75):\n","        for j in range(75):\n","            data.append([filename+'_box1_'+str(box1_row+i)+'_'+str(box1_col+j)+'_0',output[0][box1_row+i][box1_col+j]])\n","            data.append([filename+'_box1_'+str(box1_row+i)+'_'+str(box1_col+j)+'_1',output[1][box1_row+i][box1_col+j]])\n","            data.append([filename+'_box1_'+str(box1_row+i)+'_'+str(box1_col+j)+'_2',output[2][box1_row+i][box1_col+j]])\n","    for i in range(75):\n","        for j in range(75):\n","            data.append([filename+'_box2_'+str(box2_row+i)+'_'+str(box2_col+j)+'_0',output[0][box2_row+i][box2_col+j]])\n","            data.append([filename+'_box2_'+str(box2_row+i)+'_'+str(box2_col+j)+'_1',output[1][box2_row+i][box2_col+j]])\n","            data.append([filename+'_box2_'+str(box2_row+i)+'_'+str(box2_col+j)+'_2',output[2][box2_row+i][box2_col+j]])"]},{"cell_type":"markdown","metadata":{},"source":["Testing "]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T09:00:12.521895Z","iopub.status.busy":"2023-04-15T09:00:12.521485Z","iopub.status.idle":"2023-04-15T09:00:37.600414Z","shell.execute_reply":"2023-04-15T09:00:37.599311Z","shell.execute_reply.started":"2023-04-15T09:00:12.521850Z"},"trusted":true},"outputs":[],"source":["g_model = torch.load(\"/kaggle/input/my-models/g_model.pth\")\n","d_model = torch.load(\"/kaggle/input/my-models/d_model.pth\")\n","\n","import matplotlib.pyplot as plt\n","\n","outs = torch.Tensor()\n","outs = Variable(outs.type(torch.cuda.FloatTensor))\n","outs.to(device)\n","\n","with torch.no_grad():\n","    for i, (masked , filename) in enumerate(test_loader):\n","        g_out = g_model(masked)                 # Use only generator now, for making fake images (with no holes)\n","        outs = torch.cat((outs , g_out) , 0)\n","        \n","        for j in range(len(g_out)):\n","            img_tensor = g_out[j].clone()\n","            img = img_tensor.clone().add(1).div(2).mul(255).clamp(0, 255).cpu().detach().numpy()\n","            add_csv(img/255 , filename[j].split('/')[-1])   # Log into report\n","            # Uncomment all the following lines to see the full reconstructed images output by the generator\n","#             img = img.transpose(1, 2, 0).astype(\"uint8\")\n","#             if i == 0:\n","#                 print(filename[j].split('/')[-1])\n","#                 print(img.shape)\n","#                 plt.figure()\n","#                 plt.imshow(img)\n","    \n","#     print(Tensor.size(outs))\n","#     plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Just checking whether the correct model has been selected, helper code with no real use (commented)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T09:00:37.602384Z","iopub.status.busy":"2023-04-15T09:00:37.602017Z","iopub.status.idle":"2023-04-15T09:00:37.609544Z","shell.execute_reply":"2023-04-15T09:00:37.608309Z","shell.execute_reply.started":"2023-04-15T09:00:37.602348Z"},"trusted":true},"outputs":[],"source":["# with torch.no_grad():\n","#     for epoch in range(1):\n","#         for i, (masked , unmasked) in enumerate(train_loader):\n","\n","#             real_labels = Variable(torch.cuda.FloatTensor(masked.size(0),1,16,16).fill_(1.0), requires_grad=False)\n","#             real_labels.to(device)\n","\n","#             g_out = g_model(masked)\n","#             g_entropy = lossMSE(d_model(g_out) , real_labels)\n","#             g_reconstruct = lossL1(g_out , unmasked)\n","#             g_loss = 0.001 * g_entropy + 0.999 * g_reconstruct\n","\n","#             if i % CHECKPOINT_INTERVAL == 0:\n","#                 print(f\"Epoch = {epoch}, Batch = {i} , Generator Loss = {g_loss}\")\n","\n","#         print(f\"{epoch} finished\")"]},{"cell_type":"markdown","metadata":{},"source":["Save Report"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T09:00:37.614638Z","iopub.status.busy":"2023-04-15T09:00:37.614218Z","iopub.status.idle":"2023-04-15T09:00:52.263544Z","shell.execute_reply":"2023-04-15T09:00:52.262511Z","shell.execute_reply.started":"2023-04-15T09:00:37.614598Z"},"trusted":true},"outputs":[],"source":["# Convert Data to Panda dataframe\n","final_df = pd.DataFrame(data, columns=['filename_box_pixel', 'Value'])\n","# Save dataframe to report.csv and save\n","final_df.to_csv('report.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
