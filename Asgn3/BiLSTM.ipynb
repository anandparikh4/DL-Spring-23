{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T09:16:32.568566Z","iopub.status.busy":"2023-04-15T09:16:32.568191Z","iopub.status.idle":"2023-04-15T09:16:32.573999Z","shell.execute_reply":"2023-04-15T09:16:32.572538Z","shell.execute_reply.started":"2023-04-15T09:16:32.568532Z"},"id":"aPMdiGRZg3f9","trusted":true},"outputs":[],"source":["train_DIR = '/kaggle/input/photo-reconstruction/Dataset/Training_Data'\n","test_DIR = '/kaggle/input/photo-reconstruction/Dataset/Testing_Data'"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T09:16:32.716759Z","iopub.status.busy":"2023-04-15T09:16:32.716456Z","iopub.status.idle":"2023-04-15T09:16:32.722400Z","shell.execute_reply":"2023-04-15T09:16:32.721207Z","shell.execute_reply.started":"2023-04-15T09:16:32.716724Z"},"id":"_bgVmcIehn1P","trusted":true},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import ToTensor, Compose\n","from PIL import Image"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T09:16:32.725214Z","iopub.status.busy":"2023-04-15T09:16:32.724785Z","iopub.status.idle":"2023-04-15T09:16:32.734795Z","shell.execute_reply":"2023-04-15T09:16:32.733578Z","shell.execute_reply.started":"2023-04-15T09:16:32.725178Z"},"id":"bFX40gC4B1oq","trusted":true},"outputs":[],"source":["# BiLSTM Model\n","class BiLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers):\n","        super(BiLSTM, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size*2, input_size)\n","\n","    def forward(self, x):\n","        out, _ = self.lstm(x)\n","        out = self.fc(out)\n","        return out\n","\n","# LOSS FUNCTION\n","class ReconstructionLoss(nn.Module):\n","    def __init__(self):\n","        super(ReconstructionLoss, self).__init__()\n","\n","    def forward(self, output, target):\n","        return nn.MSELoss()(output, target)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T09:16:32.911200Z","iopub.status.busy":"2023-04-15T09:16:32.910861Z","iopub.status.idle":"2023-04-15T09:16:32.919081Z","shell.execute_reply":"2023-04-15T09:16:32.918000Z","shell.execute_reply.started":"2023-04-15T09:16:32.911171Z"},"id":"PnTUrxqfhthE","trusted":true},"outputs":[],"source":["# Image Dataset\n","class ImageDataset(Dataset):\n","    def __init__(self, masked_dir, unmasked_dir):\n","        self.masked_dir = masked_dir\n","        self.unmasked_dir = unmasked_dir\n","        self.transforms = Compose([ToTensor()])\n","        self.filenames = os.listdir(masked_dir)\n","        self.filenames.remove('masked_info.csv')\n","        self.masked_info = os.path.join(self.masked_dir, 'masked_info.csv')\n","    \n","    def __getitem__(self, idx):\n","        masked_path = os.path.join(self.masked_dir, self.filenames[idx])\n","        unmasked_path = os.path.join(self.unmasked_dir, self.filenames[idx])\n","        masked_image = Image.open(masked_path).convert('RGB')\n","        unmasked_image = Image.open(unmasked_path).convert('RGB')\n","        masked_tensor = self.transforms(masked_image)\n","        unmasked_tensor = self.transforms(unmasked_image)\n","        return masked_tensor, unmasked_tensor\n","\n","    def __len__(self):\n","        return len(self.filenames)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T09:36:15.617592Z","iopub.status.busy":"2023-04-15T09:36:15.617236Z","iopub.status.idle":"2023-04-15T09:36:15.643354Z","shell.execute_reply":"2023-04-15T09:36:15.642406Z","shell.execute_reply.started":"2023-04-15T09:36:15.617557Z"},"id":"GDU0XKJoCPao","trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import TensorDataset, ConcatDataset, DataLoader\n","# Define the model\n","model = BiLSTM(input_size=256, hidden_size=128, num_layers=2)\n","\n","# Define the loss function\n","loss_fn = ReconstructionLoss()\n","\n","# Define the optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# Load the data\n","cat_train_dataset = ImageDataset(masked_dir=f\"{train_DIR}/Cat/Masked_Train\", unmasked_dir=f\"{train_DIR}/Cat/Unmasked_Train\")\n","dog_train_dataset = ImageDataset(masked_dir=f\"{train_DIR}/Dog/Masked_Train\", unmasked_dir=f\"{train_DIR}/Dog/Unmasked_Train\")\n","elephant_train_dataset = ImageDataset(masked_dir=f\"{train_DIR}/Elephant/Masked_Train\", unmasked_dir=f\"{train_DIR}/Elephant/Unmasked_Train\")\n","tiger_train_dataset = ImageDataset(masked_dir=f\"{train_DIR}/Tiger/Masked_Train\", unmasked_dir=f\"{train_DIR}/Tiger/Unmasked_Train\")\n","train_dataset = ConcatDataset([cat_train_dataset, dog_train_dataset, elephant_train_dataset, tiger_train_dataset])\n","# Train Loader\n","train_loader = DataLoader(train_dataset, shuffle=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T09:36:15.645686Z","iopub.status.busy":"2023-04-15T09:36:15.645271Z","iopub.status.idle":"2023-04-15T09:36:15.650705Z","shell.execute_reply":"2023-04-15T09:36:15.649565Z","shell.execute_reply.started":"2023-04-15T09:36:15.645649Z"},"trusted":true},"outputs":[],"source":["# model = BiLSTM(input_size=256, hidden_size=128, num_layers=8)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-04-15T09:36:16.122916Z","iopub.status.busy":"2023-04-15T09:36:16.122216Z","iopub.status.idle":"2023-04-15T11:19:53.240132Z","shell.execute_reply":"2023-04-15T11:19:53.237953Z","shell.execute_reply.started":"2023-04-15T09:36:16.122877Z"},"id":"KO77Df6pt96O","outputId":"7f4c789d-f491-4259-fb04-7884c1fa6ea7","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0, MSE Loss = 126.72352881450206\n","Epoch 1, MSE Loss = 82.95575771050062\n","Epoch 2, MSE Loss = 74.48835996165872\n","Epoch 3, MSE Loss = 69.7256657514954\n","Epoch 4, MSE Loss = 67.16253951238468\n","Epoch 5, MSE Loss = 65.16681404551491\n","Epoch 6, MSE Loss = 63.41975019604433\n","Epoch 7, MSE Loss = 62.26647049782332\n","Epoch 8, MSE Loss = 61.155868933186866\n","Epoch 9, MSE Loss = 59.98875722230878\n"]}],"source":["# Train the model\n","for epoch in range(10):\n","    training_loss = 0\n","    count = 0\n","    for i, (masked, unmasked) in enumerate(train_loader):\n","        # print(masked.shape)\n","        # print(masked[0])\n","        optimizer.zero_grad()\n","        output = model(masked[0])\n","        loss = loss_fn(output, unmasked)\n","        training_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        count += 1\n","    print(f\"Epoch {epoch}, MSE Loss = {training_loss}\")\n","    torch.save(model,f'/kaggle/working/model{epoch}-8.pth')\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T11:19:53.242556Z","iopub.status.busy":"2023-04-15T11:19:53.242197Z","iopub.status.idle":"2023-04-15T11:19:53.249372Z","shell.execute_reply":"2023-04-15T11:19:53.248417Z","shell.execute_reply.started":"2023-04-15T11:19:53.242518Z"},"id":"KBvmoWwlR9dJ","trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T11:20:00.099763Z","iopub.status.busy":"2023-04-15T11:20:00.098566Z","iopub.status.idle":"2023-04-15T11:20:00.113143Z","shell.execute_reply":"2023-04-15T11:20:00.112068Z","shell.execute_reply.started":"2023-04-15T11:20:00.099708Z"},"id":"xH9EKgQg_oEI","trusted":true},"outputs":[],"source":["torch.save(model,f'/kaggle/working/bilstm.pth')"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T11:20:01.384722Z","iopub.status.busy":"2023-04-15T11:20:01.384336Z","iopub.status.idle":"2023-04-15T11:20:01.411789Z","shell.execute_reply":"2023-04-15T11:20:01.410751Z","shell.execute_reply.started":"2023-04-15T11:20:01.384686Z"},"id":"aQf8cmrm_puC","trusted":true},"outputs":[],"source":["df = pd.read_csv(f'{test_DIR}/masked_info.csv')"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T11:20:17.756448Z","iopub.status.busy":"2023-04-15T11:20:17.755457Z","iopub.status.idle":"2023-04-15T11:21:37.412802Z","shell.execute_reply":"2023-04-15T11:21:37.411775Z","shell.execute_reply.started":"2023-04-15T11:20:17.756395Z"},"id":"2Pix63Aa_jW9","trusted":true},"outputs":[],"source":["import os\n","lst = os.listdir(test_DIR)\n","lst.remove('masked_info.csv')\n","data = []\n","\n","# Test Each File in test_DIR file\n","for filename in lst:\n","  masked_path = os.path.join(test_DIR,filename)\n","#   Find All row col\n","  box1_row = df[df['filename'] == filename].iloc[0]['box1_row']\n","  box1_col = df[df['filename'] == filename].iloc[0]['box1_col']\n","  box2_row = df[df['filename'] == filename].iloc[0]['box2_row']\n","  box2_col = df[df['filename'] == filename].iloc[0]['box2_col']\n","  masked_image = Image.open(masked_path).convert('RGB')\n","  masked_tensor = Compose([ToTensor()])(masked_image)\n","  \n","  with torch.no_grad():\n","    output = model(masked_tensor)\n","  for i in range(75):\n","    for j in range(75):\n","      data.append([filename+'_box1_'+str(box1_row+i)+'_'+str(box1_col+j)+'_2',output[0][box1_row+i][box1_col+j].item()])\n","      data.append([filename+'_box1_'+str(box1_row+i)+'_'+str(box1_col+j)+'_1',output[1][box1_row+i][box1_col+j].item()])\n","      data.append([filename+'_box1_'+str(box1_row+i)+'_'+str(box1_col+j)+'_0',output[2][box1_row+i][box1_col+j].item()])\n","  for i in range(75):\n","    for j in range(75):\n","      data.append([filename+'_box2_'+str(box2_row+i)+'_'+str(box2_col+j)+'_2',output[0][box2_row+i][box2_col+j].item()])\n","      data.append([filename+'_box2_'+str(box2_row+i)+'_'+str(box2_col+j)+'_1',output[1][box2_row+i][box2_col+j].item()])\n","      data.append([filename+'_box2_'+str(box2_row+i)+'_'+str(box2_col+j)+'_0',output[2][box2_row+i][box2_col+j].item()])\n","\n","final_df = pd.DataFrame(data, columns=['filename_box_pixel', 'Value'])\n","final_df.to_csv('submission.csv',index=False)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"execution":{"iopub.execute_input":"2023-04-15T11:22:22.878911Z","iopub.status.busy":"2023-04-15T11:22:22.878002Z","iopub.status.idle":"2023-04-15T11:22:22.900351Z","shell.execute_reply":"2023-04-15T11:22:22.899192Z","shell.execute_reply.started":"2023-04-15T11:22:22.878867Z"},"id":"5miUFuqpFbVn","outputId":"751343e6-a128-4620-c3b4-9edad84b7ac0","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename_box_pixel</th>\n","      <th>Value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Dog-Train (411).jpeg_box1_21_59_2</td>\n","      <td>0.898908</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Dog-Train (411).jpeg_box1_21_59_1</td>\n","      <td>0.920529</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Dog-Train (411).jpeg_box1_21_59_0</td>\n","      <td>0.844931</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Dog-Train (411).jpeg_box1_21_60_2</td>\n","      <td>0.887779</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Dog-Train (411).jpeg_box1_21_60_1</td>\n","      <td>0.908767</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6749995</th>\n","      <td>Cat-Train (712).jpeg_box2_74_74_1</td>\n","      <td>0.515302</td>\n","    </tr>\n","    <tr>\n","      <th>6749996</th>\n","      <td>Cat-Train (712).jpeg_box2_74_74_0</td>\n","      <td>0.420458</td>\n","    </tr>\n","    <tr>\n","      <th>6749997</th>\n","      <td>Cat-Train (712).jpeg_box2_74_75_2</td>\n","      <td>0.589004</td>\n","    </tr>\n","    <tr>\n","      <th>6749998</th>\n","      <td>Cat-Train (712).jpeg_box2_74_75_1</td>\n","      <td>0.514908</td>\n","    </tr>\n","    <tr>\n","      <th>6749999</th>\n","      <td>Cat-Train (712).jpeg_box2_74_75_0</td>\n","      <td>0.420876</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6750000 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                        filename_box_pixel     Value\n","0        Dog-Train (411).jpeg_box1_21_59_2  0.898908\n","1        Dog-Train (411).jpeg_box1_21_59_1  0.920529\n","2        Dog-Train (411).jpeg_box1_21_59_0  0.844931\n","3        Dog-Train (411).jpeg_box1_21_60_2  0.887779\n","4        Dog-Train (411).jpeg_box1_21_60_1  0.908767\n","...                                    ...       ...\n","6749995  Cat-Train (712).jpeg_box2_74_74_1  0.515302\n","6749996  Cat-Train (712).jpeg_box2_74_74_0  0.420458\n","6749997  Cat-Train (712).jpeg_box2_74_75_2  0.589004\n","6749998  Cat-Train (712).jpeg_box2_74_75_1  0.514908\n","6749999  Cat-Train (712).jpeg_box2_74_75_0  0.420876\n","\n","[6750000 rows x 2 columns]"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["final_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-04-15T09:35:59.845834Z","iopub.status.idle":"2023-04-15T09:35:59.846404Z","shell.execute_reply":"2023-04-15T09:35:59.846140Z","shell.execute_reply.started":"2023-04-15T09:35:59.846112Z"},"trusted":true},"outputs":[],"source":["# Function to inpaint the masked images\n","def sample(filename,dir_path,output_image):\n","  box1_row = df[df['filename'] == filename].iloc[0]['box1_row']\n","  box1_col = df[df['filename'] == filename].iloc[0]['box1_col']\n","  box2_row = df[df['filename'] == filename].iloc[0]['box2_row']\n","  box2_col = df[df['filename'] == filename].iloc[0]['box2_col']\n","  imagepath = os.path.join(dir_path,filename)\n","  imagePIL = Image.open(imagepath).convert('RGB')\n","  image = Compose([ToTensor()])(imagePIL)\n","  output = image\n","  output[:][box1_row:box1_row+75][box1_col:box1_col+75] = output_image[:][box1_row:box1_row+75][box1_col:box1_col+75]\n","  output[:][box2_row:box2_row+75][box2_col:box2_col+75] = output_image[:][box2_row:box2_row+75][box2_col:box2_col+75]\n","  return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-04-15T09:35:59.848439Z","iopub.status.idle":"2023-04-15T09:35:59.848998Z","shell.execute_reply":"2023-04-15T09:35:59.848727Z","shell.execute_reply.started":"2023-04-15T09:35:59.848699Z"},"id":"jGAdc4TKG6Kk","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"execution":{"iopub.status.busy":"2023-04-15T09:35:59.850873Z","iopub.status.idle":"2023-04-15T09:35:59.852050Z","shell.execute_reply":"2023-04-15T09:35:59.851765Z","shell.execute_reply.started":"2023-04-15T09:35:59.851734Z"},"id":"nCz4hcokIzwF","outputId":"f0de4352-ba21-4d3a-cbdd-cdca0fe68159","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9fca-sBGeZnL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
